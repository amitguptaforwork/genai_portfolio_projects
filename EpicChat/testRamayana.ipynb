{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b70eac32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install langchain-neo4j numpy\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7687\",\n",
    "    username=\"neo4j\",\n",
    "    password=\"reform-william-center\"\n",
    ")\n",
    "\n",
    "graph.query(\"MATCH (n) DETACH DELETE n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a207f14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "providerLLMKey = os.getenv(\"OPENAI_API_KEY\")\n",
    "providerLLMKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d398b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "#Read and Parse PDF\n",
    "loader = PyPDFLoader(\"ramayana.pdf\")\n",
    "pages = loader.load()  # This returns a list of Document objects\n",
    "\n",
    "#Chunk the Text\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = splitter.split_documents(pages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d0611cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 1960 pages and 5928 chunks created.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There were {len(pages)} pages and {len(docs)} chunks created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6ca40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg EBook of The Ramayana\\nThis eBook is for the use of anyone anywhere at no cost and\\nwith almost no restrictions whatsoever. You may copy it, give\\nit away or re-use it under the terms of the Project Gutenberg\\nLicense included with this eBook or online at http://www.guten-\\nberg.org/license\\nTitle: The Ramayana\\nRelease Date: March 18, 2008 [Ebook 24869]\\nLanguage: English\\n***START OF THE PROJECT GUTENBERG EBOOK\\nTHE RAMAYANA***'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6faa536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='MERGE (the_ramayana:Document {title: \"The Ramayana\"});\\nMERGE (project_gutenberg:Organization {name: \"Project Gutenberg\"});\\nMERGE (english:Language {name: \"English\"});\\nMERGE (ebook_24869:Object {identifier: \"Ebook 24869\"});\\nMERGE (the_ramayana)-[:PUBLISHED_BY]->(project_gutenberg);\\nMERGE (the_ramayana)-[:WRITTEN_IN_LANGUAGE]->(english);\\nMERGE (the_ramayana)-[:HAS_EBOOK_VERSION]->(ebook_24869);\\nMERGE (ebook_24869)-[:RELEASE_DATE]->(:Date {date: \"2008-03-18\"});\\nMERGE (project_gutenberg)-[:HAS_LICENSE]->(:License {url: \"http://www.gutenberg.org/license\"});' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 171, 'prompt_tokens': 409, 'total_tokens': 580, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_beec22d258', 'id': 'chatcmpl-BWjfu8yPZxTl0X8SgavEzWUWOWfvP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--85831f31-72d3-4eb4-9b84-b93fdf907560-0' usage_metadata={'input_tokens': 409, 'output_tokens': 171, 'total_tokens': 580, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are an expert at converting narrative texts into structured knowledge graphs using Neo4j's Cypher query language. \n",
    "Given is an excerpt from a document (e.g., a section of the Ramayana), \n",
    "\n",
    "Extract the relevant entities (characters, places, events) and relationships (e.g., is father of, traveled to, fought with), \n",
    "then represent them as Cypher MERGE statements suitable for insertion into a Neo4j database.\n",
    "\n",
    "Example\n",
    "Input: In the Ramayana, Rama is the son of King Dasharatha and Queen Kausalya. He was born in Ayodhya.\n",
    "\n",
    "Cypher:\n",
    "MERGE  (rama:Character {{name: \"Rama\"}});\n",
    "MERGE  (sita:Character {{name: \"Sita\"}});\n",
    "MERGE  (ayodhya:Place {{name: \"Ayodhya\"}});\n",
    "MERGE  (rama)-[:MARRIED_TO]->(sita);\n",
    "MERGE  (rama)-[:BORN_IN]->(ayodhya);\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "Node labels can be Character, Place, Event, Object, etc.\n",
    "Relationship types should be descriptive and in uppercase (e.g., :BROTHER_OF, :TRAVELED_TO).\n",
    "Use MERGE instead of CREATE when the same entity appears more than once to avoid duplication.\n",
    "Focus only on facts explicitly stated or strongly implied in the text.\n",
    "Do not include speculation or inferred emotions.\n",
    "\n",
    "Input: {text}\n",
    "Cypher:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=template)\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\",temperature=0)\n",
    "\n",
    "chain = prompt|llm\n",
    "response = chain.invoke({\"text\": docs[0].page_content})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "761319cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j  import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7687\",  # or your remote instance\n",
    "    username=\"neo4j\",\n",
    "    password=\"reform-william-center\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
